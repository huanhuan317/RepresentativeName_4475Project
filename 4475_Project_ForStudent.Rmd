```{r}
require(tidyverse)
require(data.table)
require(randomForest)
require(mclust)
require(rpart)
require(rpart.plot)
require(foreign)
require(e1071)
```
Selection
#Data Source
#https://www.kaggle.com/datasets/whenamancodes/credit-card-customers-prediction

Pre-processing
```{r}
#é¦–å…ˆï¼Œæˆ‘å…ˆè¯»å–æ•°æ®BankChurners.csvï¼Œnew_customï¼Œnew_customer
data1 <- read.csv("BankChurners.csv")
data2 <- read.csv("new_custom.csv")
data3 <- read.csv("new_customer.csv")
#å¤‡ä»½
cleasing1<-data1
cleasing2<-data2
cleasing3<-data3
#missing data
sum(is.na(cleasing1))
sum(is.na(cleasing2))
sum(is.na(cleasing3))
cleasing1
cleasing2
cleasing3
```

Excellent: 0-10% utilization
Good: 10-30% utilization
Fair: 30-50% utilization
Poor: 50% or higher utilization
Transformation
```{r}

```

```{r}
#ï¼ˆuseingcleasing1 ï¼‰
Transform <- cleasing1
Transform <- data.frame(
  Avg_Utilization_Ratio = c(0.061, 0.105, 0.000, 0.760, 0.000, 0.311, 0.066, 0.048)
)
Transform$Util_Rank <- character(nrow(Transform))  
for (i in 1:nrow(Transform)) {
  ratio <- Transform$Avg_Utilization_Ratio[i]
  if (ratio >= 0 && ratio <= 0.10) {
    Transform$Util_Rank[i] <- "Excellent"
  } else if (ratio > 0.10 && ratio <= 0.30) {
    Transform$Util_Rank[i] <- "Good"
  } else if (ratio > 0.30 && ratio <= 0.50) {
    Transform$Util_Rank[i] <- "Fair"
  } else if (ratio > 0.50) {
    Transform$Util_Rank[i] <- "Poor"
  } else {
    Transform$Util_Rank[i] <- NA_character_  
  }
}
Transform
```

```{r}
# å“å‘€ï¼Œåé¢éœ€è¦è¿™ä¸ªï¼Œæˆ‘æŠŠä»–ä»¬ä¸€ä¸€åŒ¹é…è¿›å»
data1$Util_Rank <- character(nrow(data1))  

for (i in 1:nrow(data1)) {
  ratio <- data1$Avg_Utilization_Ratio[i]
  if (ratio >= 0 && ratio <= 0.10) {
    data1$Util_Rank[i] <- "Excellent"
  } else if (ratio > 0.10 && ratio <= 0.30) {
    data1$Util_Rank[i] <- "Good"
  } else if (ratio > 0.30 && ratio <= 0.50) {
    data1$Util_Rank[i] <- "Fair"
  } else if (ratio > 0.50) {
    data1$Util_Rank[i] <- "Poor"
  } else {
    data1$Util_Rank[i] <- NA_character_
  }
}

#æ–°çš„data1
data1
```

Descriptive Analysis
Question1 - Basic Aggregration
```{r}
#Summarise the average credit limit by different card type
# Get all unique card typesï¼ˆUseing cleasing1 ï¼‰
Card_Category <- unique(cleasing1$Card_Category)  
Card_Category
# Results storage
avg_credit_limit <- numeric(length(Card_Category))  
avg_credit_limit
# Iterate over card types and calculate average credit limits
for (i in seq_along(Card_Category)) {
  # Filtering data for the current card type
  subset_data <- cleasing1[cleasing1$Card_Category == Card_Category[i], ]  
  # Calculation of average credit limits (ignoring missing values)
  avg_credit_limit[i] <- mean(subset_data$Credit_Limit, na.rm = TRUE)  
}
# Collation results
result_credit <- data.frame(
  Card_Category = Card_Category, 
  Avg_Credit_Limit = avg_credit_limit
)
# result
result_credit
#count the number of different education level

education_levels <- unique(cleasing1$Education_Level)  
education_levels
# Results storage
edu_count <- numeric(length(education_levels)) 
# Traversing the level of education and counting the number of clients
for (i in seq_along(education_levels)) {
  # Statistics on the number of clients at the current level of education (ignoring missing values)
  edu_count[i] <- sum(cleasing1$Education_Level == education_levels[i], na.rm = TRUE)  
}
# Collate results into dataframes
result_edu <- data.frame(
  Education_Level = education_levels, 
  Count = edu_count
)
#result
result_edu
#Summaries Average of Open to buy all Income Category
# Access to a unique income category
income_categories <- unique(cleasing1$Income_Category)
# Results storageğŸ˜
avg_open_to_buy <- numeric(length(income_categories))
# Calculated averageâ€œAvg_Open_To_Buyâ€
for (i in seq_along(income_categories)) {
  # Filtering data for the current income category
  subset_data <- cleasing1[cleasing1$Income_Category == income_categories[i], ]
  # Calculation of the average "Avg_Open_To_Buy"
  avg_open_to_buy[i] <- mean(subset_data$Avg_Open_To_Buy, na.rm = TRUE)
}
# Collate results into dataframes
result_open_to_buy <- data.frame(
  Income_Category = income_categories,
  Avg_Open_To_Buy = avg_open_to_buy
)
# output
result_open_to_buy

```

Question2 - Basic statics (Bar)
```{r}
# Sort data frame by Avg_Open_To_Buy descending order
sorted_result <- result_open_to_buy[order(-result_open_to_buy$Avg_Open_To_Buy), ]

# 3. bar
barplot(
  height = sorted_result$Avg_Open_To_Buy,  # y-axis data (sorted)
  names.arg = sorted_result$Income_Category,  # x-axis labels (sorted)
  xlab = "Income Category", 
  ylab = "Average OTP (Open to Pay)", 
  main = "Average OTP by Income Category (Sorted Descending)", 
  col = "grey", 
  las = 2,  # Rotating x-axis labels
  cex.names = 0.8, 
  ylim = c(0, max(sorted_result$Avg_Open_To_Buy, na.rm = TRUE) * 1.1)
)


text(
  x = barplot(sorted_result$Avg_Open_To_Buy, plot = FALSE), 
  y = sorted_result$Avg_Open_To_Buy + 500, 
  labels = round(sorted_result$Avg_Open_To_Buy, 2), 
  cex = 0.8, 
  col = "black"
)
```

Question3 - Basic statics (pie)
```{r}
# ç»Ÿè®¡ä¸åŒæ•™è‚²èµ„æ ¼çš„å®¢æˆ·æ•°é‡ï¼ŒåŒæ—¶æŒ‡å®šç±»åˆ«é¡ºåºï¼ŒæŒ‰ç…§å›¾ç‰‡æ¥çš„ï¼Œï¼Œï¼Œï¼Œï¼Œ
edu_order <- c("Graduate", "High School", "Unknown", 
               "Uneducated", "College", "Post-Graduate", "Doctorate")
edu_counts <- table(factor(cleasing1$Education_Level, levels = edu_order))

# å®šä¹‰é¢œè‰²å‘é‡ï¼ŒæŒ‰ç…§å›¾ç‰‡é¡ºåºï¼Œå“å‘€ï¼Œæ²¡æœ‰ç´«è‰²ï¼Œåªèƒ½å¼„ä¸ªgreyçœ‹çœ‹ã€‚
colors <- c("white", "lightblue", "pink", "lightyellow", "grey", "lightcyan", "gray")

pie(
  edu_counts,
  labels = paste(names(edu_counts), "\n", edu_counts, "äºº (", #sooooo,äººæ˜¯ä¸ªä»€ä¹ˆï¼Ÿ
                 round(edu_counts / sum(edu_counts) * 100, 2), "%)", sep = ""),
  main = "Customer Education Qualification Proportion",
  col = colors
)
```

Question4 - Relation(scatter)
```{r}
# useing cleasing1ï¼Œis Total_Trans_Amt and  Total_Trans_Ct 
x <- data1$Total_Trans_Amt  
y <- data1$Total_Trans_Ct   

#1.scatter
plot(
  x, y, 
  xlab = "Transform$Total_Trans_Amt",     
  ylab = "Total_Trans_Ct",      
  main = "Relation between Credit Transaction Amount and Count",  
  pch = 16,                     
  col = "black",                
  cex = 0.6                     
)

# 2. Adding a Linear Fit Line
model <- lm(y ~ x)  # linear regression model,soooooooo
abline(model, col = "red", lwd = 1)  # Plotting the fitted line (red, line width [çœ‹å›¾ç‰‡æ„Ÿè§‰æ˜¯1])

# 3. Calculate and add RÂ² values
r_squared <- summary(model)$r.squared
text(
  x = max(x) * 0.6,  # æ–‡æœ¬ä½ç½®ï¼ˆxè½´60%å¤„ï¼‰[æ„Ÿè§‰æ˜¯åœ¨60%å·¦å³ï¼Œx.yéƒ½æ˜¯ä¸€æ ·çš„]
  y = max(y) * 0.6,  # æ–‡æœ¬ä½ç½®ï¼ˆyè½´60%å¤„ï¼‰
  labels = bquote(R^2 == .(round(r_squared, 2))),  # æ˜¾ç¤º RÂ²
  cex = 1.2          # The font size is about the same.
)
```


https://www.digitalocean.com/community/tutorials/normalize-data-in-r
https://stats.stackexchange.com/questions/298507/mclust-model-names-corresponding-to-common-models-i-e-those-used-for-lpa-lc
Modelname EEE = Equal variances and equal covariances
if you want to make the clustering like a matrix, try to use modelname EEE
Question5 - Clustering
```{r}

X <- data1[, c("Total_Trans_Ct", "Customer_Age")]  

# 2. æ•°æ®é¢„å¤„ç†ï¼ˆåŸºç¡€ç‰ˆï¼‰

# å¤„ç†ç¼ºå¤±å€¼ï¼ˆå¡«ä¸­ä½æ•°ï¼‰
for (col in names(X)) {
  X[[col]][is.na(X[[col]])] <- median(X[[col]], na.rm = TRUE)
}

# æ ‡å‡†åŒ–ï¼ˆZ-scoreï¼‰
for (col in names(X)) {
  X[[col]] <- (X[[col]] - mean(X[[col]])) / sd(X[[col]])
}

# ========================
# 3. K-means èšç±»ï¼ˆ4 ç±»ï¼‰
# ========================
set.seed(123)
model <- kmeans(X, centers = 4)
cluster_assign <- model$cluster

# 4. å¯è§†åŒ–ï¼ˆä¸¥æ ¼åŒ¹é…ç›®æ ‡å›¾ï¼‰

# å®šä¹‰é¢œè‰²å’Œå½¢çŠ¶ï¼ˆç›®æ ‡å›¾æ ·å¼ï¼‰
colors <- c("green", "purple", "blue", "red")  
shapes <- c(17, 3, 16, 14)   #å°å°ä¸‰è§’å½¢ï¼Œ+ï¼Œblueå®å¿ƒçš„å°åœ†ç‚¹ï¼Œredç©ºå¿ƒæ–¹å—ï¼Œå“å‘€ï¼Œæˆ‘æŸ¥äº†èµ„æ–™æ˜¯14ï¼Œä½†æ˜¯å®ƒæ€ä¹ˆå‡ºç°äº†ä¸€ä¸ªå°å…«

# ç»˜åˆ¶æ•£ç‚¹å›¾
plot(
  x = data1$Total_Trans_Ct, 
  y = data1$Customer_Age, 
  pch = shapes[cluster_assign], 
  col = colors[cluster_assign], 
  xlab = "Transform.Total_Trans_Ct",
  ylab = "Transform.Customer_Age",
  main = "Clustering: Classify four types of credit card users",
  cex = 0.8
)

# æ·»åŠ èšç±»æ¤­åœ† + é»‘è‰²åå­—äº¤å‰ 
for (k in 1:4) {
  cluster_data <- data1[cluster_assign == k, c("Total_Trans_Ct", "Customer_Age")]
  mean_ct <- mean(cluster_data$Total_Trans_Ct)
  mean_age <- mean(cluster_data$Customer_Age)
  cov_mat <- cov(cluster_data)
  
  # ç»˜åˆ¶æ¤­åœ†ï¼ˆåŸé€»è¾‘ï¼‰
  theta <- seq(0, 2*pi, length.out = 100)
  ellipse <- cbind(
    mean_ct + sqrt(cov_mat[1,1])*cos(theta),
    mean_age + sqrt(cov_mat[2,2])*sin(theta)
  )
  lines(ellipse, col = "black", lwd = 1)
  
  
#Add a black cross (+ shape)

  cross_size <- max(sqrt(cov_mat[1,1]), sqrt(cov_mat[2,2])) * 0.1
  segments(
    x0 = mean_ct - cross_size, y0 = mean_age, 
    x1 = mean_ct + cross_size, y1 = mean_age, 
    col = "black", lwd = 1
  )
  segments(
    x0 = mean_ct, y0 = mean_age - cross_size, 
    x1 = mean_ct, y1 = mean_age + cross_size, 
    col = "black", lwd = 1
  )
  


}
```

Question6 - pattern finding(CART tree)
```{r}
library(rpart)
library(rpart.plot)
# åˆ›å»ºå†³ç­–æ ‘æ¨¡å‹
decision_tree <- rpart(Util_Rank ~ Income_Category + Total_Revolving_Bal, 
                        data = data1, 
                        method = "class")


print(decision_tree)


rpart.plot(decision_tree, main = "Credit Card Utilization Decision Tree")

```

Question7 - classification(Naive Bias)
```{r}
library(e1071)
#NB Classification
train_data <- data1
# 
train_data$Util_Rank <- as.factor(train_data$Util_Rank)

# Training a plain Naive Bias
nb_model <- naiveBayes(
  Util_Rank ~ .,  
  data = train_data
)
#new customers
new_customers <- data2

#make an enquiry
predictions <- predict(nb_model, newdata = new_customers)
#aiya~~~~~,what ?
predictions


```

Question8 - Prediction/simulation (random Forest)
```{r}

#model building
data1$Credit_Limit <- as.factor(data1$Credit_Limit)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆåŸä»£ç ï¼‰
set.seed(123)
train_idx <- sample(nrow(data1), nrow(data1) * 0.7)
train_data <- data1[train_idx, ]
test_data <- data1[-train_idx, ]

# å…³é”®ä¿®å¤ï¼šæ£€æŸ¥å¹¶è¿‡æ»¤ç©ºç±»åˆ«
cat("è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š\n")
print(table(train_data$Credit_Limit))
# åªä¿ç•™æœ‰æ ·æœ¬çš„ç±»åˆ«
train_data <- train_data[train_data$Credit_Limit %in% names(which(table(train_data$Credit_Limit) > 0)), ]
# é‡æ–°è½¬æ¢ä¸ºå› å­ï¼Œç¡®ä¿ç±»åˆ«æ­£ç¡®ï¼ˆå› ä¸ºè¿‡æ»¤åç±»åˆ«å¯èƒ½å˜åŒ–ï¼‰
train_data$Credit_Limit <- as.factor(train_data$Credit_Limit)


cat("ä¿®å¤åè®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒï¼š\n")
print(table(train_data$Credit_Limit))

# æ¨¡å‹æ„å»ºï¼ˆé‡æ–°è®­ç»ƒï¼‰
set.seed(456)
rf_model <- randomForest(
  Credit_Limit ~ Income_Category + Customer_Age, 
  data = train_data,
  ntree = 500, 
  importance = TRUE
)

# åç»­æµ‹è¯•ä»£ç ï¼ˆåŸä»£ç ä¸å˜ï¼‰
#model testing
test_pred <- predict(rf_model, newdata = test_data)
conf_mat <- table(test_data$Credit_Limit, test_pred)
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
print(conf_mat)
cat("æ¨¡å‹å‡†ç¡®ç‡ï¼š", accuracy, "\n")

#choose one row data for testing
new_customer <- data.table(
  Income_Category = "Medium",  
  Customer_Age = 35            
)

new_customer_pred <- predict(rf_model, newdata = new_customer)
print("æ–°å®¢æˆ·ä¿¡ç”¨é¢åº¦åˆ†ç±»é¢„æµ‹ç»“æœï¼š")
print(new_customer_pred)
```

Evualtion
```{r}
# åŠ è½½å¿…è¦çš„åŒ…
require(tidyverse)
require(data.table)
require(randomForest)
library(data.table)


# æ•°æ®é¢„å¤„ç†
# ç¡®ä¿Credit_Limitåˆ—æ˜¯å› å­ç±»å‹
data1$Credit_Limit <- as.factor(data1$Credit_Limit)

# æ£€æŸ¥ç±»åˆ«åˆ†å¸ƒï¼Œç¡®ä¿æ²¡æœ‰ç©ºç±»åˆ«
cat("ç±»åˆ«åˆ†å¸ƒæ£€æŸ¥ï¼š\n")
print(table(data1$Credit_Limit))

# åˆå¹¶æˆ–è¿‡æ»¤ç½•è§ç±»åˆ«ï¼ˆå¦‚æœæœ‰ï¼‰
# ç¤ºä¾‹ï¼šåˆå¹¶Lowå’ŒMediumç±»åˆ«
# data1$Credit_Limit[data1$Credit_Limit %in% c("Low", "Medium")] <- "Low-Medium"
# data1$Credit_Limit <- as.factor(data1$Credit_Limit)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
set.seed(123)
train_idx <- sample(nrow(data1), nrow(data1) * 0.7)
train_data <- data1[train_idx, ]
test_data <- data1[-train_idx, ]

# æ¨¡å‹æ„å»º
set.seed(456)
rf_model <- randomForest(
  Credit_Limit ~ Income_Category + Customer_Age,
  data = train_data,
  ntree = 500,
  importance = TRUE
)

# ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
varImpPlot(rf_model)

# æ¨¡å‹æµ‹è¯•
test_pred <- predict(rf_model, newdata = test_data)
conf_mat <- table(test_data$Credit_Limit, test_pred)
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)

cat("\næ¨¡å‹è¯„ä¼°ç»“æœï¼š\n")
print(conf_mat)
cat("æ¨¡å‹å‡†ç¡®ç‡ï¼š", accuracy, "\n")

# æ–°å®¢æˆ·é¢„æµ‹ç¤ºä¾‹
# ç¡®ä¿ç‰¹å¾ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„ç‰¹å¾ä¸€è‡´
new_customer <- data.table(
  Income_Category = "Medium",  # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
  Customer_Age = 35            # æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹
)

new_customer_pred <- predict(rf_model, newdata = new_customer)
cat("\næ–°å®¢æˆ·ä¿¡ç”¨é¢åº¦é¢„æµ‹ç»“æœï¼š", new_customer_pred, "\n")    
```

#Write you finding in Report, Thanks!
